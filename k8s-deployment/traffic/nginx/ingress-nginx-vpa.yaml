apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: ingress-nginx-vpa
  namespace: ingress-nginx
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ingress-nginx-controller
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: "ingress-nginx-controller"
    # Note: This is more stable compared to HPA, which may not be as reliable.
    # Additionally, this approach helps reduce latency for ingress-nginx (same as ingress-nginx-hpa) and is more effective in preventing NGINX bottlenecks.
    # When NGINX becomes a bottleneck, its memory usage increases (e.g., average usage between 500 MiB ~ 1 GiB++). If the memory usage is under 500 MiB (e.g., average usage between 500 MiB ~ 250MiB or lower) , it is considered stable.
    # This indicates that the target deployment (not the NGINX deployment) cannot handle high traffic or a large number of requests.
      minAllowed:
        cpu: 50m
        memory: 50Mi
      maxAllowed:
    # When the CPU usage in VPA reaches 2000m ~ 3000m, the average vCPU usage on pods should be around 700m ~ 1000m, indicating stability at a large scale if memory usage is under 500 MiB.
    # Ratio:
    # An average of 400m ~ 600m on pods (with VPA reaching 920m) is stable for handling 5 nodes (each with an average of 4 vCPUs) without latency issues, such as high response times or timeouts,
    # which can affect other deployments and those using HPA.
        cpu: 4
        memory: 2Gi
      controlledResources: ["cpu", "memory"]
